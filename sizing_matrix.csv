Model,Quantization,Users,Latency Target (s),GPUs Needed,GPU Type,RAM (GB),CPUs
LLaMA2-7B,int8,10,<1,1,A100 40GB,128,16
LLaMA2-13B,int4,5,<2,1,A100 80GB,192,24
LLaMA2-13B,fp16,10,<1,2,A100 80GB,256,32
LLaMA2-70B,int4,5,<2,4,H100 80GB,512,64
Mistral-7B,int8,20,<1,1,L40S,96,12
Gemma-7B,int4,15,<1,1,RTX A6000,128,16
Mixtral-8x7B,int4,5,<2,4,H100 80GB,640,80
LLaMA 3-70B,int8,5,<2,4,H100 80GB,768,80
LLaMA 3-70B,fp16,2,<1,8,H100 80GB,1024,96
LLaMA 3-400B (Maverick),int4,2,<3,16,H100 80GB,2048,128
LLaMA 3-400B (Maverick),fp16,1,<2,32,H100 80GB,3072,160
Claude 3 Opus,int8,5,<2,8,H100 80GB (NVLink),1024,96
Claude 3 Opus,fp16,2,<1,16,H100 80GB (NVLink),1536,128
GPT-3.5,int8,10,<1,4,A100 80GB (NVLink),512,64
GPT-3.5,fp16,5,<1,8,A100 80GB (NVLink),768,96
GPT-4 (est. 400B),int4,2,<3,16,H100 80GB (NVLink),2048,128
GPT-4 (est. 400B),fp16,1,<2,32,H100 80GB (NVLink),3072,160
Command R+,int8,5,<2,2,L40S (NVLink),256,32
Command R+,fp16,2,<1,4,L40S (NVLink),384,48
LLaMA2-13B,int4,5,<2,2,L40S,160,20
LLaMA2-13B,int4,5,<2,1,RTX 6000 Ada,128,16
LLaMA2-70B,int4,3,<2,8,A100 80GB (NVLink),768,72
LLaMA2-70B,int4,3,<2,8,GH200 Grace Hopper,1024,96
GPT-3.5,int8,10,<1,4,RTX 6000 Ada,512,64
Claude 3 Opus,int8,5,<2,4,GH200 Grace Hopper,768,80
Claude 3 Opus,int8,5,<2,4,MI300X,768,80
LLaMA 3-400B (Maverick),int4,2,<3,16,MI300X,2048,128
